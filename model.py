# -*- coding: utf-8 -*-
"""Untitled29.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CWhzW14_6Az5YK7b0sG6ZQvZ-hARt2XZ
"""

# Step 1: Import Libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer

# Step 2: Load the Dataset
file_path = 'restaurant_data.csv'
data = pd.read_csv(file_path)

# Display the first few rows of the dataset
# print(data.head())

# Step 3: Data Preprocessing
# 3.1 Handling Missing Values
imputer = SimpleImputer(strategy='mean')  # or 'median', 'most_frequent', etc.
data[['prep_time', 'order_backlog', 'historical_preparation_time']] = imputer.fit_transform(
    data[['prep_time', 'order_backlog', 'historical_preparation_time']]
)

# 3.2 Encoding Categorical Variables
label_encoder = LabelEncoder()
data['restaurant_name'] = label_encoder.fit_transform(data['restaurant_name'])
data['food_item'] = label_encoder.fit_transform(data['food_item'])
data['time_of_the_day'] = label_encoder.fit_transform(data['time_of_the_day'])
data['is_on_route'] = label_encoder.fit_transform(data['is_on_route'])

# 3.3 Feature Scaling
scaler = StandardScaler()
numeric_columns = ['prep_time', 'order_backlog', 'historical_preparation_time',
                   'latitude', 'longitude', 'estimated_time_arrival',
                   'user_travel_time', 'actual_preparation_time']
data[numeric_columns] = scaler.fit_transform(data[numeric_columns])

# 3.4 Splitting the Dataset
X = data.drop('actual_preparation_time', axis=1)  # Features
y = data['actual_preparation_time']  # Target variable

# Split into training and testing sets (e.g., 80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Display shapes of the training and testing sets
# print("Training set shape:", X_train.shape)
# print("Testing set shape:", X_test.shape)


# Step 3: Implementing Gradient Boosting
# Initialize the model
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score


gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Train the model
gb_model.fit(X_train, y_train)

# Step 4: Model Evaluation
# Predict on the test set
y_pred = gb_model.predict(X_test)

# Calculate performance metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# print("\nModel Evaluation:")
# print(f"Mean Squared Error: {mse:.2f}")
# print(f"RÂ² Score: {r2:.2f}")

# Optional: Display feature importances
feature_importances = gb_model.feature_importances_
importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

import joblib

# Step 5: Save the trained model to a file
model_filename = 'gradient_boosting_model.pkl'  # You can choose any name
joblib.dump(gb_model, model_filename)

print(f"Model saved to {model_filename}")


import pandas as pd
import numpy as np

# Load your dataset (make sure you provide the correct path)
file_path = 'restaurant_data.csv'  # Update this path
data = pd.read_csv(file_path)

# Function to calculate distance based on latitude and longitude
def calculate_distance(lat1, lon1, lat2, lon2):
    # Using the Haversine formula to calculate the distance
    R = 6371  # Radius of the Earth in kilometers
    dlat = np.radians(lat2 - lat1)
    dlon = np.radians(lon2 - lon1)
    a = (np.sin(dlat / 2) ** 2 +
         np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dlon / 2) ** 2)
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))
    distance = R * c
    return distance

# Fixed starting point
pickup_location = (17.496654, 78.373186)

# Get user input for food item
selected_food_item = input("Enter the food item you want to order: ")

# Calculate distances and filter restaurants
results = []

for index, row in data.iterrows():
    if row['food_item'].lower() == selected_food_item.lower():  # Case-insensitive match
        restaurant_location = (row['latitude'], row['longitude'])
        distance = calculate_distance(pickup_location[0], pickup_location[1], restaurant_location[0], restaurant_location[1])

        # Calculate estimated time of arrival (6 minutes per kilometer)
        estimated_arrival_time = distance * 6  # in minutes

        # Check if the estimated arrival time is greater than or equal to the preparation time
        if (estimated_arrival_time >= row['prep_time']) & (row['is_on_route'] == 'Yes'):
            results.append((row['restaurant_name'], estimated_arrival_time))

# Display results
if results:

    print(f"\nRestaurants serving '{selected_food_item}':")
    for restaurant_name, eta in results:

        print(f"Restaurant: {restaurant_name}, Estimated Time of Arrival: {eta:.2f} minutes")

else:
    print(f"No restaurants found serving '{selected_food_item}' that can meet the estimated time or on route.")